{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../../../../Desktop/Orthografietrainer2020/pickle/'\n",
    "infile = open(path+'umfrage2020only.pkl','rb')\n",
    "umfrage = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "#Deutschnote: bereinigen\n",
    "umfrage['deutschnote'] = umfrage['deutschnote'].replace(['Es gab keine Noten', np.nan],0)\n",
    "umfrage['deutschnote'] = umfrage['deutschnote'].astype('int')\n",
    "# Erstschrift: deutsch=1, nicht deutsch=0\n",
    "umfrage['ErstSchrift'] = umfrage['ErstSchrift'].replace([np.nan,'Russisch','Serbisch','Englisch','Italienisch','Vietnamesisch','Persisch','Kroatisch','Polnisch','Kurdisch','Arabisch','Griechisch','Spanisch','Niederl&auml;ndisch','T&uuml;rkisch','eine andere, und zwar...'],0)\n",
    "umfrage['ErstSchrift'] = umfrage['ErstSchrift'].replace(['Deutsch'],1)\n",
    "#Eigsprache: deutsch=1, nicht deutsch=0\n",
    "umfrage['eigSprache'] = umfrage['eigSprache'].replace([np.nan,'Russisch','Serbisch','Englisch','Italienisch','Vietnamesisch','Persisch','Kroatisch','Polnisch','Kurdisch','Arabisch','Griechisch','Spanisch','Niederl&auml;ndisch','T&uuml;rkisch','eine andere, und zwar...'],0)\n",
    "umfrage['eigSprache'] = umfrage['eigSprache'].replace(['Deutsch'],1)\n",
    "\n",
    "# Sprache mutter: deutsch = 1, nicht deutsch = 0\n",
    "umfrage['SpracheMutter'] = umfrage['SpracheMutter'].replace([np.nan,'Russisch','Serbisch','Englisch','Italienisch','Vietnamesisch','Persisch','Kroatisch','Polnisch','Kurdisch','Arabisch','Griechisch','Spanisch','Niederl&auml;ndisch','T&uuml;rkisch','eine andere, und zwar...'],0)\n",
    "umfrage['SpracheMutter'] = umfrage['SpracheMutter'].replace(['Deutsch'],1)\n",
    "\n",
    "# Sprache mutter: deutsch = 1, nicht deutsch = 0\n",
    "umfrage['SpracheVater'] = umfrage['SpracheVater'].replace([np.nan,'Russisch','Serbisch','Englisch','Italienisch','Vietnamesisch','Persisch','Kroatisch','Polnisch','Kurdisch','Arabisch','Griechisch','Spanisch','Niederl&auml;ndisch','T&uuml;rkisch','eine andere, und zwar...'],0)\n",
    "umfrage['SpracheVater'] = umfrage['SpracheVater'].replace(['Deutsch'],1)\n",
    "\n",
    "#Abieltern: weißnicht = nan\n",
    "umfrage['AbiEltern'] = umfrage['AbiEltern'].replace(['weissnicht'],np.nan)\n",
    "\n",
    "#Buecher\n",
    "umfrage['Buecher'] = umfrage['Buecher'].replace(['10'],0)\n",
    "umfrage['Buecher'] = umfrage['Buecher'].replace(['50'],1)\n",
    "umfrage['Buecher'] = umfrage['Buecher'].replace(['100'],2)\n",
    "umfrage['Buecher'] = umfrage['Buecher'].replace(['200'],3)\n",
    "\n",
    "\n",
    "li = ['freizeit_Fernsehen','fach_Spanisch', 'freizeit_Freunde',\n",
    "       'fach_Sport', 'freizeit_Internet','freizeit_Kino', 'fach_Biologie', \n",
    "       'freizeit_Lesen', 'fach_Chemie', 'fach_keinLieblingsfach',\n",
    "       'freizeit_Musikhoeren', 'fach_DS', 'fach_keineAngabe',\n",
    "       'freizeit_Musikmachen', 'fach_Deutsch', 'freizeit_Basteln',\n",
    "       'freizeit_Schreiben', 'fach_Englisch', 'freizeit_Computerspiele',\n",
    "       'freizeit_Shopping', 'fach_Franzoesisch', 'freizeit_Familie','freizeit_Sport', 'fach_Geografie',\n",
    "       'fach_Politik', 'freizeit_Tanzen', 'fach_Geschichte',\n",
    "       'freizeit_Theater', 'fach_Handarbeit', \n",
    "       'fach_Informatik', 'freizeit_kaumFreizeit', 'fach_Kunst', \n",
    "       'fach_Musik', 'fach_Physik', 'freizeit_keineAngabe',\n",
    "       'fach_Mathematik', 'fach_Sozialkunde', 'fach_Religion']\n",
    "\n",
    "for x in li:\n",
    "    umfrage[x] = umfrage[x].fillna(0)\n",
    "    umfrage[x] = umfrage[x].astype('int')\n",
    "\n",
    "\n",
    "#umfrage = umfrage.drop(columns=['klassenstufe', 'geschlecht', 'eigSpracheAndere','ErstSchriftAndere', 'SpracheMutterAndere','SpracheVaterAndere'])\n",
    "\n",
    "b = [  'SchreibenGern', 'SchreibenLeicht','deutschnote',\n",
    "       'eigSprache', 'ErstSchrift', 'SpracheMutter', 'LesenGern',\n",
    "       'SpracheVater', 'LesenLeicht']#'AbiEltern',\n",
    "\n",
    "for i in b:\n",
    "    umfrage[i] = umfrage[i].astype('float32')\n",
    "    umfrage[i] = umfrage[i].fillna(umfrage[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>UserID</th>\n",
       "      <th>AbiEltern</th>\n",
       "      <th>BedeutungNoten</th>\n",
       "      <th>SchreibenGern</th>\n",
       "      <th>Buecher</th>\n",
       "      <th>bundesland</th>\n",
       "      <th>SchreibenLeicht</th>\n",
       "      <th>klassenstufe</th>\n",
       "      <th>freizeit_Fernsehen</th>\n",
       "      <th>deutschnote</th>\n",
       "      <th>...</th>\n",
       "      <th>fach_Informatik</th>\n",
       "      <th>freizeit_kaumFreizeit</th>\n",
       "      <th>fach_Kunst</th>\n",
       "      <th>geburtsjahr</th>\n",
       "      <th>fach_Musik</th>\n",
       "      <th>fach_Physik</th>\n",
       "      <th>freizeit_keineAngabe</th>\n",
       "      <th>fach_Mathematik</th>\n",
       "      <th>fach_Sozialkunde</th>\n",
       "      <th>fach_Religion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geschlecht</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>2519</td>\n",
       "      <td>1408</td>\n",
       "      <td>1804</td>\n",
       "      <td>2519</td>\n",
       "      <td>1816</td>\n",
       "      <td>2479</td>\n",
       "      <td>2519</td>\n",
       "      <td>2471</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>...</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>2449</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "      <td>2519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>2591</td>\n",
       "      <td>1633</td>\n",
       "      <td>1999</td>\n",
       "      <td>2591</td>\n",
       "      <td>2022</td>\n",
       "      <td>2544</td>\n",
       "      <td>2591</td>\n",
       "      <td>2550</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>...</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>2528</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable    UserID  AbiEltern  BedeutungNoten  SchreibenGern  Buecher  \\\n",
       "geschlecht                                                              \n",
       "d               42         26              34             42       34   \n",
       "m             2519       1408            1804           2519     1816   \n",
       "w             2591       1633            1999           2591     2022   \n",
       "\n",
       "variable    bundesland  SchreibenLeicht  klassenstufe  freizeit_Fernsehen  \\\n",
       "geschlecht                                                                  \n",
       "d                   39               42            40                  42   \n",
       "m                 2479             2519          2471                2519   \n",
       "w                 2544             2591          2550                2591   \n",
       "\n",
       "variable    deutschnote  ...  fach_Informatik  freizeit_kaumFreizeit  \\\n",
       "geschlecht               ...                                           \n",
       "d                    42  ...               42                     42   \n",
       "m                  2519  ...             2519                   2519   \n",
       "w                  2591  ...             2591                   2591   \n",
       "\n",
       "variable    fach_Kunst  geburtsjahr  fach_Musik  fach_Physik  \\\n",
       "geschlecht                                                     \n",
       "d                   42           40          42           42   \n",
       "m                 2519         2449        2519         2519   \n",
       "w                 2591         2528        2591         2591   \n",
       "\n",
       "variable    freizeit_keineAngabe  fach_Mathematik  fach_Sozialkunde  \\\n",
       "geschlecht                                                            \n",
       "d                             42               42                42   \n",
       "m                           2519             2519              2519   \n",
       "w                           2591             2591              2591   \n",
       "\n",
       "variable    fach_Religion  \n",
       "geschlecht                 \n",
       "d                      42  \n",
       "m                    2519  \n",
       "w                    2591  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umfrage.groupby('geschlecht').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'sitzungssummary.pkl','rb')\n",
    "sitzungen = pickle.load(infile)\n",
    "infile.close()\n",
    "sitzungen = sitzungen [['ID','UserID','UserAttribut','Art','HA','beendet','Fehler']]\n",
    "\n",
    "sitzungen = sitzungen.dropna()\n",
    "sitzungen.rename(columns = {'ID':'UebungsID'}, inplace = True)\n",
    "# Userattribut: 1=Schüler; 0= Gast/ Lehrer\n",
    "sitzungen['UserAttribut'] = sitzungen['UserAttribut'].replace(['Schüler'],1)\n",
    "sitzungen['UserAttribut'] = sitzungen['UserAttribut'].replace(['Gast','Lehrer'],0)\n",
    "sitzungen[['UserAttribut']] = sitzungen[['UserAttribut']].astype('int16')\n",
    "#HA: bereinigung\n",
    "sitzungen['HA'] = sitzungen['HA'].replace(['frHA'],'Self')\n",
    "\n",
    "infile = open(path+'saetze.pkl','rb')\n",
    "saetze = pickle.load(infile)\n",
    "infile.close()\n",
    "saetze = saetze[['satzID','Schwierigkeit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'schueler2020only.pkl','rb')\n",
    "schueler = pickle.load(infile)\n",
    "infile.close()\n",
    "schueler = schueler[['ID','Geschlecht','Klassenstufe','Anmeldeklassenstufe','Aufgaben','Altaufgaben','done']]\n",
    "\n",
    "schueler.rename(columns = {'ID':'UserID'}, inplace = True)\n",
    "schueler['done'] = schueler['done'].astype('int16')\n",
    "#Geschlecht: bereinigung\n",
    "schueler['Geschlecht'] = schueler['Geschlecht'].replace(['m.','armin.zekan@hakamste'],'m')\n",
    "schueler['Geschlecht'] = schueler['Geschlecht'].replace(['w.','we'],'w')\n",
    "schueler['Geschlecht'] = schueler['Geschlecht'].replace(['d','wm'],np.nan)\n",
    "#Klassenstufe: nutze nur Klassenstufe 5-12\n",
    "options = ['5', '6','7','8','9','10','11','12'] \n",
    "schueler = schueler[schueler['Klassenstufe'].isin(options)] \n",
    "schueler['Klassenstufe'] = schueler['Klassenstufe'].astype('int')\n",
    "#Jahredabei: erstelle aus Klassenstufe - Anmeldeklassenstufe die Spalte Jahredabei\n",
    "schueler = schueler[schueler['Anmeldeklassenstufe'].isin(options)] \n",
    "schueler['Anmeldeklassenstufe'] = schueler['Anmeldeklassenstufe'].astype('int')\n",
    "schueler['Jahredabei'] = schueler['Klassenstufe'] - schueler['Anmeldeklassenstufe']\n",
    "#Anzahlaufgaben: erstelle Spalte, die angibt, wie viele Aufgaben dem User aktuell zugeordnet sind\n",
    "schueler['Aufgaben']=schueler['Aufgaben'].str.split()\n",
    "schueler['AnzahlAufgaben'] = schueler['Aufgaben'].str.len()\n",
    "schueler['AnzahlAufgaben'] = schueler['AnzahlAufgaben'].replace([np.nan],0)\n",
    "schueler['AnzahlAufgaben'] = schueler['AnzahlAufgaben'].astype('int')\n",
    "# Lösche \n",
    "schueler= schueler.drop(columns=['Anmeldeklassenstufe','Aufgaben','Altaufgaben'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'xmlsaetze.pkl','rb')\n",
    "xmlsaetze = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsaetze = xmlsaetze[['ID','UserID','UebungsID','Testposition','SatzID','Erstloesung','Schussel','Datum', 'Erfolg','Loesungsnr']]\n",
    "\n",
    "infile = open(path+'xmlsaetze_archiv.pkl','rb')\n",
    "xmlsaetze_archiv = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsaetze_archiv = xmlsaetze_archiv[['ID','UserID','UebungsID','Testposition','SatzID','Erstloesung','Schussel','Datum', 'Erfolg','Loesungsnr']]\n",
    "\n",
    "xmlsaetze = xmlsaetze.append(xmlsaetze_archiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlsaetze.rename(columns = {'SatzID':'satzID'}, inplace = True)\n",
    "xmlsaetze= pd.merge(xmlsaetze, saetze, on='satzID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(xmlsaetze, umfrage, on='UserID')\n",
    "df = pd.merge(df, sitzungen, on='UebungsID')\n",
    "df.rename(columns = {'UserID_x':'UserID'}, inplace = True)\n",
    "\n",
    "df = pd.merge(df, schueler, on='UserID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4600"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.UserID.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datum']= pd.to_datetime(df['Datum'])\n",
    "df['Uhrzeit'] = pd.DatetimeIndex(df['Datum']).hour\n",
    "df['Wochentag'] = pd.DatetimeIndex(df['Datum']).dayofweek\n",
    "df['Kalenderwoche'] = pd.DatetimeIndex(df['Datum']).strftime(\"%V\")\n",
    "df['Monat'] = pd.DatetimeIndex(df['Datum']).month\n",
    "df['Tag'] = pd.DatetimeIndex(df['Datum']).day\n",
    "\n",
    "df = df[(df.Testposition == 'version') | (df.Testposition == 'pruefung') | (df.Testposition == 'training')]\n",
    "df = df[(df.Monat == 3) | (df.Monat == 4)|(df.Monat == 5) | (df.Monat == 6)]\n",
    "\n",
    "#Merge xmlsaetze mit saetze\n",
    "def f(row):\n",
    "    if row['Uhrzeit'] > 14:\n",
    "        val = 0\n",
    "    elif row['Uhrzeit'] < 8:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "df['ist_Schulzeit'] = df.apply(f, axis=1)\n",
    "df = df.drop(columns='UserID')\n",
    "\n",
    "# variable mehrfach falsch\n",
    "df['Loesungsnr']=df['Loesungsnr'].str.split()\n",
    "df['MehrfachFalsch'] = df['Loesungsnr'].str.len()\n",
    "df['MehrfachFalsch'] = df['MehrfachFalsch'].replace([np.nan],0)\n",
    "df['MehrfachFalsch'] = df['MehrfachFalsch'].astype('int')\n",
    "df['MehrfachFalsch'] = df['MehrfachFalsch'] - 1\n",
    "\n",
    "df.to_pickle('fairness_preprocessing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordernumber and Lücke finden\n",
    "sitzungen = df.UebungsID.unique()\n",
    "ordernumbers =pd.DataFrame(columns=['OrderNumber', 'ID'])\n",
    "for i in sitzungen:\n",
    "    subset = df.loc[df['UebungsID'] == i]\n",
    "    subset = subset.sort_values(by='Datum')\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    subset.reset_index(inplace=True)\n",
    "    subset = subset.rename(columns = {'index':'OrderNumber'})\n",
    "    subset = subset[['OrderNumber','ID']]\n",
    "    ordernumbers = ordernumbers.append(subset)\n",
    "\n",
    "df = pd.merge(df,ordernumbers,on='ID', how='left')\n",
    "df['OrderNumber'] = df['OrderNumber'] + 1\n",
    "df.to_pickle('fairness_ordernumber.pkl')\n",
    "\n",
    "df['Time'] = pd.DatetimeIndex(df['Datum']).strftime(\"%X\")\n",
    "\n",
    "# Finde die Sessions, in denen eine Lücke von Monaten / Tagen oder mehr als 45 Minuten Uhrzeit ist\n",
    "df_gr = df.groupby('UebungsID').agg({'Monat': ['min', 'max'], 'Tag': ['min', 'max'], 'Time': ['min', 'max']})\n",
    "df_gr = df_gr.reset_index()\n",
    "\n",
    "def f(row):\n",
    "    if row.Monat['min'] != row.Monat['max']:\n",
    "        val = 1\n",
    "    elif  row.Tag['min'] != row.Tag['max']:\n",
    "        val = 1\n",
    "    elif  row.Time['min'] != row.Time['max']:\n",
    "        if ((pd.to_datetime(row.Time['min']) + pd.to_timedelta(45, unit='m')) < pd.to_datetime(row.Time['max'])):\n",
    "            val = 1\n",
    "        else:\n",
    "            val = 0\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "df_gr['luecke'] = df_gr.apply(f, axis=1)\n",
    "\n",
    "df_gr.to_pickle('fairness_luecke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-8569dae751f2>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fairness_luecke0['sessionNr'] = 1\n",
      "<ipython-input-9-8569dae751f2>:46: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  xml_with_breaks.loc[(xml_with_breaks.ID.values == id1.values), 'sessionNr'] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18551502\n",
      "19522658\n",
      "20103741\n",
      "20103742\n",
      "21968089\n",
      "22585724\n",
      "21789794\n",
      "21789792\n",
      "21789791\n",
      "19049882\n",
      "19772797\n",
      "19772796\n",
      "19788393\n",
      "19788389\n",
      "19788392\n",
      "19788391\n",
      "19788388\n",
      "14609587\n",
      "17756591\n",
      "22005086\n",
      "22005087\n",
      "21987788\n",
      "21987789\n",
      "19994692\n",
      "19701039\n",
      "19701041\n",
      "20233717\n",
      "18236115\n",
      "19161784\n",
      "18236114\n",
      "18427838\n"
     ]
    }
   ],
   "source": [
    "infile = open('fairness_luecke.pkl','rb')\n",
    "fairness_luecke = pickle.load(infile)\n",
    "infile.close()\n",
    "fairness_luecke.columns = fairness_luecke.columns.droplevel(1)\n",
    "fairness_luecke = fairness_luecke[['UebungsID','luecke']]\n",
    "\n",
    "infile = open('fairness_ordernumber.pkl','rb')\n",
    "fairness_ordernumber = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "fairness_merged = pd.merge(fairness_ordernumber, fairness_luecke, on='UebungsID')\n",
    "\n",
    "fairness_luecke0 = fairness_merged[fairness_merged.luecke==0]\n",
    "fairness_luecke1 = fairness_merged[fairness_merged.luecke==1]\n",
    "\n",
    "fairness_luecke0['sessionNr'] = 1\n",
    "\n",
    "#Variable Sessionnr hinzufügen\n",
    "\n",
    "def f(aktuelltag, aktuellmonat, aktuelluhrzeit, vergleichtag, vergleichmonat, vergleichuhrzeit):\n",
    "    if aktuellmonat.values[0] != vergleichmonat.values[0]:\n",
    "        val = 1\n",
    "    elif  aktuelltag.values[0] != vergleichtag.values[0]:\n",
    "        val = 1\n",
    "    elif  aktuelluhrzeit.values[0] != vergleichuhrzeit.values[0]:\n",
    "        if (vergleichuhrzeit.values[0]+3) < aktuelluhrzeit.values[0]:\n",
    "            val = 1\n",
    "        else:\n",
    "            val= 0\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "errorlist = []\n",
    "\n",
    "xml_with_breaks = fairness_luecke1\n",
    "xml_with_breaks = xml_with_breaks.astype({'UebungsID': str})\n",
    "xml_with_breaks['sessionNr'] = 0\n",
    "sitzungen = xml_with_breaks.UebungsID.unique()\n",
    "for x in sitzungen:\n",
    "    try:\n",
    "        anzahl = len(xml_with_breaks.loc[xml_with_breaks['UebungsID'] == x])\n",
    "\n",
    "        nr1 = xml_with_breaks.loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)] \n",
    "        id1 = nr1.ID\n",
    "        xml_with_breaks.loc[(xml_with_breaks.ID.values == id1.values), 'sessionNr'] = 1\n",
    "\n",
    "        vergleichmonat = xml_with_breaks['Monat'].loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)] \n",
    "        vergleichtag = xml_with_breaks['Tag'].loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)]    \n",
    "        vergleichuhrzeit = xml_with_breaks['Uhrzeit'].loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)] \n",
    "\n",
    "        session = 1\n",
    "\n",
    "        for y in range(anzahl-1):\n",
    "            a = y+2\n",
    "            nr = xml_with_breaks.loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == a)]\n",
    "            this_id = nr.ID\n",
    "\n",
    "            aktuelltag = nr['Tag']\n",
    "            aktuellmonat = nr['Monat']\n",
    "            aktuelluhrzeit = nr['Uhrzeit']\n",
    "\n",
    "            is_break = f(aktuelltag, aktuellmonat, aktuelluhrzeit, vergleichtag, vergleichmonat, vergleichuhrzeit)\n",
    "\n",
    "            if is_break == 1:\n",
    "                xml_with_breaks.loc[(xml_with_breaks.ID.values == this_id.values), 'sessionNr'] = session+1\n",
    "                session = session+1\n",
    "            else:\n",
    "                xml_with_breaks.loc[(xml_with_breaks.ID.values == this_id.values), 'sessionNr'] = session\n",
    "\n",
    "            vergleichmonat = aktuellmonat\n",
    "            vergleichtag = aktuelltag\n",
    "            vergleichuhrzeit = aktuelluhrzeit\n",
    "\n",
    "    except:\n",
    "        print(x)\n",
    "\n",
    "xml_with_breaks.to_pickle('fairness_sessionnr1.pkl')\n",
    "fairness_luecke0.to_pickle('fairness_sessionnr0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('fairness_sessionnr1.pkl','rb')\n",
    "fairness_sessionnr1 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open('fairness_sessionnr0.pkl','rb')\n",
    "fairness_sessionnr0 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "new_session_nr = fairness_sessionnr1.append(fairness_sessionnr0)\n",
    "\n",
    "# Add SessionNr to UebungsID -> macht neue UebungsID pro Session\n",
    "new_session_nr['sessionNr'] = new_session_nr['sessionNr'].astype(str)\n",
    "new_session_nr[\"UebungsID\"] = new_session_nr[\"UebungsID\"].map(str) + \"_\" + new_session_nr[\"sessionNr\"]\n",
    "\n",
    "# Berechne Ordnernummer neu ( Wenn Session getrennt, muss Session 2 wieder mit ordernr 1 anfangen)\n",
    "min_ordernr = new_session_nr.groupby('UebungsID')['OrderNumber'].min()\n",
    "new_order = pd.merge(new_session_nr, min_ordernr, on='UebungsID')\n",
    "new_order['OrderNumber_y'] = new_order['OrderNumber_y'] - 1\n",
    "new_order['OrderNumber'] = new_order['OrderNumber_x'] - new_order['OrderNumber_y']\n",
    "\n",
    "new_order = new_order.drop(columns=['OrderNumber_x', 'OrderNumber_y'])\n",
    "\n",
    "# Neue Spalte: wenn es sich um die zweite/ dritte/ vierte Session in der Aufgabe handelt -> vorher schonmal abgebrochen = 1\n",
    "def f(row):\n",
    "    if row['sessionNr'] != '1':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "new_order['vorher_abgebrochen'] = new_order.apply(f, axis=1)\n",
    "new_order.to_pickle('fairness_vacay.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f1e475680c28>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  luecke_0['testpos_prue'] = np.where(luecke_0['Testposition']== 'pruefung', 1, 0)\n",
      "<ipython-input-11-f1e475680c28>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  luecke_0['testpos_train'] = np.where(luecke_0['Testposition']== 'training', 1, 0)\n",
      "<ipython-input-11-f1e475680c28>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  luecke_0['testpos_vers'] = np.where(luecke_0['Testposition']== 'version', 1, 0)\n"
     ]
    }
   ],
   "source": [
    "infile = open('fairness_vacay.pkl','rb')\n",
    "df_new = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "\n",
    "df_new['temp_ueb'] = df_new['UebungsID'].map(lambda x: str(x)[:-2])\n",
    "luecke_0 = df_new[df_new.luecke == 0]\n",
    "\n",
    "luecke_0['testpos_prue'] = np.where(luecke_0['Testposition']== 'pruefung', 1, 0)\n",
    "luecke_0['testpos_train'] = np.where(luecke_0['Testposition']== 'training', 1, 0)\n",
    "luecke_0['testpos_vers'] = np.where(luecke_0['Testposition']== 'version', 1, 0)\n",
    "luecke_0_grouped = luecke_0.groupby('UebungsID').agg({'Erfolg': ['count', 'sum'], 'MehrfachFalsch': ['sum'], 'luecke': ['first'], 'sessionNr':['first'], 'vorher_abgebrochen':['first'],'temp_ueb':['first'], 'beendet' : ['first'], 'testpos_prue':['sum'], 'testpos_train':['sum'], 'testpos_vers':['sum']})\n",
    "\n",
    "def f(row):\n",
    "    if row.testpos_train['sum'] < 10:\n",
    "        val = 0\n",
    "    elif  row.testpos_train['sum'] >= 10:\n",
    "        if (row.testpos_train['sum'] == 10) and (row.Erfolg['sum'] == 10):\n",
    "            val = 1\n",
    "        elif ((row.Erfolg['count']-row.testpos_prue['sum']) == row.Erfolg['sum']) and ((row.testpos_vers['sum']/2+10) ==  row.testpos_train['sum']): #standardweg für Fehler im Training\n",
    "            val = 1\n",
    "        elif ((row.Erfolg['count']-row.Erfolg['sum']) == row.testpos_prue['sum']):\n",
    "            val = 1\n",
    "        elif ((row.Erfolg['count']-row.Erfolg['sum']+1) == row.testpos_prue['sum']):\n",
    "            val = 1\n",
    "        elif (row.testpos_vers['sum']>0) and (row.testpos_prue['sum']==0):\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 3\n",
    "    else:\n",
    "        val = 3\n",
    "    return val\n",
    "\n",
    "luecke_0_grouped['y'] = luecke_0_grouped.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d9e585b25a95>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  luecke_1['testpos_prue'] = np.where(luecke_1['Testposition']== 'pruefung', 1, 0)\n",
      "<ipython-input-12-d9e585b25a95>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  luecke_1['testpos_train'] = np.where(luecke_1['Testposition']== 'training', 1, 0)\n",
      "<ipython-input-12-d9e585b25a95>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  luecke_1['testpos_vers'] = np.where(luecke_1['Testposition']== 'version', 1, 0)\n"
     ]
    }
   ],
   "source": [
    "luecke_1 = df_new[df_new.luecke == 1]\n",
    "\n",
    "luecke_1['testpos_prue'] = np.where(luecke_1['Testposition']== 'pruefung', 1, 0)\n",
    "luecke_1['testpos_train'] = np.where(luecke_1['Testposition']== 'training', 1, 0)\n",
    "luecke_1['testpos_vers'] = np.where(luecke_1['Testposition']== 'version', 1, 0)\n",
    "\n",
    "max_session = luecke_1.groupby('temp_ueb')['sessionNr'].max()\n",
    "max_session=max_session.reset_index()\n",
    "max_session.columns = ['temp_ueb', 'maxSession']\n",
    "\n",
    "luecke_1 = pd.merge(luecke_1, max_session, on='temp_ueb')\n",
    "luecke_1_grouped = luecke_1.groupby('UebungsID').agg({'Erfolg': ['count', 'sum'], 'MehrfachFalsch': ['sum'], 'luecke': ['first'], 'sessionNr':['first'], 'maxSession':['first'], 'vorher_abgebrochen':['first'],'temp_ueb':['first'], 'beendet' : ['first'], 'testpos_prue':['sum'], 'testpos_train':['sum'], 'testpos_vers':['sum']})\n",
    "luecke_1_grouped_full = luecke_1.groupby('temp_ueb').agg({'Erfolg': ['count', 'sum'], 'MehrfachFalsch': ['sum'], 'luecke': ['first'], 'sessionNr':['min'], 'maxSession':['max'], 'vorher_abgebrochen':['max'],  'testpos_prue':['sum'], 'testpos_train':['sum'], 'testpos_vers':['sum']})\n",
    "\n",
    "def f(row):\n",
    "    if row.testpos_train['sum'] < 10:\n",
    "        val = 0\n",
    "    elif  row.testpos_train['sum'] >= 10:\n",
    "        if (row.testpos_train['sum'] == 10) and (row.Erfolg['sum'] == 10):\n",
    "            val = 1\n",
    "        elif ((row.Erfolg['count']-row.testpos_prue['sum']) == row.Erfolg['sum']) and ((row.testpos_vers['sum']/2+10) ==  row.testpos_train['sum']): #standardweg für Fehler im Training\n",
    "            val = 1\n",
    "        elif ((row.Erfolg['count']-row.Erfolg['sum']) == row.testpos_prue['sum']):\n",
    "            val = 1\n",
    "        elif ((row.Erfolg['count']-row.Erfolg['sum']+1) == row.testpos_prue['sum']):\n",
    "            val = 1\n",
    "        elif (row.testpos_vers['sum']>0) and (row.testpos_prue['sum']==0):\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 3\n",
    "    else:\n",
    "        val = 3\n",
    "    return val\n",
    "\n",
    "luecke_1_grouped_full['y_all'] = luecke_1_grouped_full.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "luecke_1_grouped_full.columns = luecke_1_grouped_full.columns.droplevel(1)\n",
    "luecke_1_grouped_full = luecke_1_grouped_full.reset_index()\n",
    "luecke_1_grouped_full = luecke_1_grouped_full[['temp_ueb','y_all']]\n",
    "\n",
    "luecke_1_grouped.columns = luecke_1_grouped.columns.droplevel(1)\n",
    "luecke_1_grouped.columns.values[1] = \"Erfolg_count\"\n",
    "luecke_1_grouped = luecke_1_grouped.reset_index()\n",
    "\n",
    "luecke_1_grouped_merged = pd.merge(luecke_1_grouped, luecke_1_grouped_full, on='temp_ueb')\n",
    "\n",
    "def f(row):\n",
    "    if row.maxSession == '1' and row.y_all == 1:\n",
    "        val = 1\n",
    "    elif row.maxSession == '1' and row.y_all == 0:\n",
    "        val = 0\n",
    "    elif row.maxSession != '1':\n",
    "        if (row.y_all == 1) and (row.maxSession == row.sessionNr) :\n",
    "            val=1\n",
    "        else:\n",
    "            val=0\n",
    "    else:\n",
    "        val = 3\n",
    "    return val\n",
    "\n",
    "luecke_1_grouped_merged['y'] = luecke_1_grouped_merged.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "luecke_0_grouped.columns = luecke_0_grouped.columns.droplevel(1)\n",
    "luecke_0_grouped = luecke_0_grouped.reset_index()\n",
    "luecke_0_grouped = luecke_0_grouped[['UebungsID','y']]\n",
    "luecke_1_grouped_merged = luecke_1_grouped_merged[['UebungsID','y']]\n",
    "predictors = luecke_0_grouped.append(luecke_1_grouped_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.to_pickle('fairness_predictors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('fairness_vacay.pkl','rb')\n",
    "fairness_vacay = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(fairness_vacay, predictors, on='UebungsID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sitzungen\n",
    "dummy_Art = pd.get_dummies(df['Art'], prefix='Art_')\n",
    "df = pd.merge(left=df, right=dummy_Art,left_index=True,right_index=True)\n",
    "#HA\n",
    "dummy_HA = pd.get_dummies(df['HA'], prefix='HA_')\n",
    "df = pd.merge(left=df, right=dummy_HA,left_index=True,right_index=True)\n",
    "#Geschlecht\n",
    "dummy_Geschlecht = pd.get_dummies(df['Geschlecht'], prefix='Sex_')\n",
    "df = pd.merge(left=df, right=dummy_Geschlecht,left_index=True,right_index=True)\n",
    "#Testposition\n",
    "dummy_Testposition = pd.get_dummies(df['Testposition'], prefix='Testposition_')\n",
    "df = pd.merge(left=df, right=dummy_Testposition,left_index=True,right_index=True)\n",
    "\n",
    "#Lösche unnötige Spalten\n",
    "df = df.drop(columns=['Art','HA'])\n",
    "df= df.drop(columns=['Geschlecht','Testposition'])\n",
    "\n",
    "df_1 = df[df.y == 1]\n",
    "df_0 = df[df.y == 0]\n",
    "\n",
    "df_ready = df_1.append(df_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row.OrderNumber <= 10:\n",
    "        val = row.OrderNumber -10\n",
    "    elif row.OrderNumber <=14:\n",
    "        val = row.OrderNumber -14\n",
    "    elif row.OrderNumber <=18:\n",
    "        val = row.OrderNumber -18\n",
    "    elif row.OrderNumber <=22:\n",
    "        val = row.OrderNumber -22\n",
    "    elif row.OrderNumber <=26:\n",
    "        val = row.OrderNumber -26\n",
    "    elif row.OrderNumber <=30:\n",
    "        val = row.OrderNumber -30\n",
    "    elif row.OrderNumber <=34:\n",
    "        val = row.OrderNumber -34\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "df_ready['steps'] = df_ready.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ready = df_ready.drop(columns=['Schwierigkeit_x', 'Schwierigkeit_y'])\n",
    "\n",
    "df_ready.to_pickle('fairness_ready.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
