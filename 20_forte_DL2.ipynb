{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "from typing import Tuple\r\n",
    "from tensorflow.keras.datasets import mnist\r\n",
    "from tensorflow.keras.initializers import Constant\r\n",
    "from tensorflow.keras.initializers import TruncatedNormal\r\n",
    "from tensorflow.keras.layers import Activation\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import cohen_kappa_score\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# baseline model\r\n",
    "def build_model():\r\n",
    "\t# create model\r\n",
    "\tmodel = Sequential()\r\n",
    "\tmodel.add(Dense(24, input_dim=24, activation='relu'))\r\n",
    "\tmodel.add(Dense(48, activation='relu'))\r\n",
    "\tmodel.add(Dense(24, activation='relu'))\r\n",
    "\tmodel.add(Dense(12, activation='relu'))\r\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\r\n",
    "\t\t\r\n",
    "\treturn model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "accuracyDL= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\r\n",
    "metricsDL_buecher0= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_buecher1= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_buecher2= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_buecher3= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_bedeutung1= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_bedeutung2= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_bedeutung3= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "metricsDL_bedeutung4= pd.DataFrame(columns=['Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC'])\r\n",
    "\r\n",
    "n = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\r\n",
    "feature_cols = ['Erstloesung','Schussel','Erfolg', 'Schwierigkeit', 'ist_Schulzeit', 'MehrfachFalsch', 'vorher_abgebrochen','Fehler', 'Klassenstufe', 'Jahredabei', 'AnzahlAufgaben', 'Sex__m', 'Sex__w', 'Testposition__pruefung', 'Testposition__training','Testposition__version', 'Art__GK', 'Art__GR', 'Art__GZ', 'Art__K', 'Art__LB','UserAttribut', 'OrderNumber', 'steps']\r\n",
    "#\r\n",
    "for i in n:\r\n",
    "    path='matrices_allsessions/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\r\n",
    "\r\n",
    "    model = build_model()\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        loss=\"binary_crossentropy\",\r\n",
    "        optimizer='Adam',\r\n",
    "        metrics=[\"accuracy\"]\r\n",
    "    )\r\n",
    "\r\n",
    "    model.fit(\r\n",
    "        x=X_train,\r\n",
    "        y=y_train,\r\n",
    "        epochs=10,\r\n",
    "        batch_size=128,\r\n",
    "        verbose=0,\r\n",
    "        validation_data=(X_test, y_test)\r\n",
    "    )\r\n",
    "\r\n",
    "    scores = model.evaluate(\r\n",
    "        x=X_test,\r\n",
    "        y=y_test,\r\n",
    "        verbose=0\r\n",
    "    )\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X_test, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X_test) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\r\n",
    "    precision = precision_score(y_test, yhat_classes)\r\n",
    "    recall = recall_score(y_test, yhat_classes)\r\n",
    "    f1 = f1_score(y_test, yhat_classes)\r\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\r\n",
    "    \r\n",
    "    accuracyDL = accuracyDL.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "    accuracyDL.to_pickle('accuracyDL.pkl')\r\n",
    "\r\n",
    "    ## Bedeutung Noten\r\n",
    "    path='matrices_bedeutung1/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_bedeutung1 = metricsDL_bedeutung1.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "    path='matrices_bedeutung2/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_bedeutung2 = metricsDL_bedeutung2.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "\r\n",
    "    path='matrices_bedeutung3/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_bedeutung3 = metricsDL_bedeutung3.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "\r\n",
    "    path='matrices_bedeutung4/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_bedeutung4 = metricsDL_bedeutung4.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "\r\n",
    "    #Buecher\r\n",
    "    path='matrices_buecher_0/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_buecher0 = metricsDL_buecher0.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "    path='matrices_buecher_1/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_buecher1 = metricsDL_buecher1.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "\r\n",
    "    path='matrices_buecher_2/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_buecher2 = metricsDL_buecher2.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "\r\n",
    "    path='matrices_buecher_3/matrix'+str(i)+'.pkl'\r\n",
    "    infile = open(path,'rb')\r\n",
    "    df = pickle.load(infile)\r\n",
    "    infile.close()\r\n",
    "    df=df.reset_index()\r\n",
    "    y_len = len(feature_cols)\r\n",
    "    X = df[feature_cols].astype(float)\r\n",
    "    y = df.y\r\n",
    "    y= y.astype('int')\r\n",
    "\r\n",
    "    yhat_probs = model.predict(X, verbose=0)\r\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\r\n",
    "    # reduce to 1d array\r\n",
    "    yhat_probs = yhat_probs[:, 0]\r\n",
    "    yhat_classes = yhat_classes[:, 0]\r\n",
    "\r\n",
    "    accuracy = accuracy_score(y, yhat_classes)\r\n",
    "    precision = precision_score(y, yhat_classes)\r\n",
    "    recall = recall_score(y, yhat_classes)\r\n",
    "    f1 = f1_score(y, yhat_classes)\r\n",
    "    auc = roc_auc_score(y, yhat_probs)\r\n",
    "    metricsDL_buecher3 = metricsDL_buecher3.append({'Sentence': i, 'Accuracy':accuracy,'Precision': precision, 'Recall':recall, 'F1':f1, 'AUC':auc}, ignore_index=True)\r\n",
    "\r\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "metricsDL_buecher0 = metricsDL_buecher0.add_prefix('buecher0_')\r\n",
    "metricsDL_buecher0 = metricsDL_buecher0.rename(columns = {'buecher0_Sentence':'Sentence'}, inplace = False)\r\n",
    "metricsDL_buecher1 = metricsDL_buecher1.add_prefix('buecher1_')\r\n",
    "metricsDL_buecher1 = metricsDL_buecher1.rename(columns = {'buecher1_Sentence':'Sentence'}, inplace = False)\r\n",
    "metricsDL_buecher2 = metricsDL_buecher2.add_prefix('buecher2_')\r\n",
    "metricsDL_buecher2 = metricsDL_buecher2.rename(columns = {'buecher2_Sentence':'Sentence'}, inplace = False)\r\n",
    "metricsDL_buecher3 = metricsDL_buecher3.add_prefix('buecher3_')\r\n",
    "metricsDL_buecher3 = metricsDL_buecher3.rename(columns = {'buecher3_Sentence':'Sentence'}, inplace = False)\r\n",
    "\r\n",
    "\r\n",
    "metrics_buecher = pd.merge(metricsDL_buecher1, metricsDL_buecher2, on='Sentence')\r\n",
    "metrics_buecher = pd.merge(metrics_buecher, metricsDL_buecher3, on='Sentence')\r\n",
    "metrics_buecher = pd.merge(metrics_buecher, metricsDL_buecher0, on='Sentence')\r\n",
    "\r\n",
    "metrics_buecher.to_excel('metrics_buecherDL.xlsx')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "metricsDL_bedeutung1 = metricsDL_bedeutung1.add_prefix('bedeutung1_')\r\n",
    "metricsDL_bedeutung1 = metricsDL_bedeutung1.rename(columns = {'bedeutung1_Sentence':'Sentence'}, inplace = False)\r\n",
    "metricsDL_bedeutung2 = metricsDL_bedeutung2.add_prefix('bedeutung2_')\r\n",
    "metricsDL_bedeutung2 = metricsDL_bedeutung2.rename(columns = {'bedeutung2_Sentence':'Sentence'}, inplace = False)\r\n",
    "metricsDL_bedeutung3 = metricsDL_bedeutung3.add_prefix('bedeutung3_')\r\n",
    "metricsDL_bedeutung3 = metricsDL_bedeutung3.rename(columns = {'bedeutung3_Sentence':'Sentence'}, inplace = False)\r\n",
    "metricsDL_bedeutung4 = metricsDL_bedeutung4.add_prefix('bedeutung4_')\r\n",
    "metricsDL_bedeutung4 = metricsDL_bedeutung4.rename(columns = {'bedeutung4_Sentence':'Sentence'}, inplace = False)\r\n",
    "\r\n",
    "\r\n",
    "metrics_bedeutung = pd.merge(metricsDL_bedeutung1, metricsDL_bedeutung2, on='Sentence')\r\n",
    "metrics_bedeutung = pd.merge(metrics_bedeutung, metricsDL_bedeutung3, on='Sentence')\r\n",
    "metrics_bedeutung = pd.merge(metrics_bedeutung, metricsDL_bedeutung4, on='Sentence')\r\n",
    "\r\n",
    "metrics_bedeutung.to_excel('metrics_bedeutungDL.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "150bee6449ec23b191e7730f25546f1ad4023e8075f204418de6a30a8b144c22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}